{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdbb3dad-8dd6-4a25-b1f2-fdd345a27b1c",
   "metadata": {},
   "source": [
    "## Implementing new PyTensor Ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad4f97f-f484-4f1d-bcc3-8e2fb1703009",
   "metadata": {},
   "source": [
    "In [PyTensor from Scratch](../walkthrough/pytensor_from_scratch.ipynb) we saw a simplified versino of how to implement some Ops. \n",
    "\n",
    "This was almost exactly like real PyTensor Ops except we didn't use the real objects, and the perform method should store the results in a provided output storage instead of returning them. Here is how the Sum could be implemented in real PyTensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58691dd3-374d-4404-bc86-7acd7d96f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "try:\n",
    "    import pytensor_workshop\n",
    "except ImportError:\n",
    "    !pip install git+https://github.com/pytensor-devs/pytensor-workshop.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f4ba27-3f97-456b-aadf-233db2def8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytensor_workshop import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1195b46-a766-4340-bf59-76192766ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytensor\n",
    "import pytensor.tensor as pt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd76ebae-0d1c-4c14-8742-66d666f290d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytensor.graph.basic import Apply\n",
    "from pytensor.graph.op import Op\n",
    "from pytensor.tensor.type import TensorType, scalar\n",
    "from pytensor.graph import rewrite_graph\n",
    "\n",
    "class Sum(Op):\n",
    "    \n",
    "    def make_node(self, x):\n",
    "        assert isinstance(x.type, TensorType)\n",
    "        out = scalar(dtype=x.type.dtype)\n",
    "        return Apply(self, [x], [out])\n",
    "\n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        [x] = inputs\n",
    "        [out] = output_storage\n",
    "        out[0] = x.sum()\n",
    "\n",
    "sum = Sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b47e4bc9-f34b-4983-b4fe-32625abc2ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum [id A]\n",
      " └─ <Matrix(float64, shape=(?, ?))> [id B]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7f5b4e591c00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = TensorType(shape=(None, None), dtype=\"float64\")()\n",
    "sum_x = sum(x)\n",
    "sum_x.dprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bca574e6-e755-41b7-bc6e-2279b2e83a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_x.eval({x: np.ones((2, 3))})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80384a58-4a4a-4cd6-98da-58d1babefe9a",
   "metadata": {},
   "source": [
    "### Exercises 1: Implement a Transpose Op\n",
    "\n",
    "Implement a transpose Op that flips the dimensions of an input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa1e9ead-1558-4544-81dd-a7a915cfea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transpose(Op):\n",
    "    \n",
    "    def make_node(self, x):\n",
    "        ...\n",
    "\n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        ...\n",
    "    \n",
    "\n",
    "@test\n",
    "def test_transpose_op(op_class):\n",
    "    op = op_class()\n",
    "    x = pt.tensor(\"x\", shape=(2, 3, 4), dtype=\"float32\")\n",
    "    out = op(x)\n",
    "\n",
    "    assert out.type.shape == (4, 3, 2)\n",
    "    assert out.type.dtype == x.type.dtype\n",
    "    x_test = np.arange(2 * 3 * 4).reshape((2, 3, 4)).astype(x.type.dtype)\n",
    "    np.testing.assert_allclose(out.eval({x: x_test}), x_test.T)\n",
    "\n",
    "# test_transpose_op(Transpose)  # uncomment me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f98cfc9-4c1f-478b-a607-92bea4398fc2",
   "metadata": {},
   "source": [
    "### Exercise 2: Parametrize transpose axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e7670-2ef4-431d-9e64-caeefc48b1d7",
   "metadata": {},
   "source": [
    "Extend transpose to allow arbitrary transposition axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5179e71b-09e9-4eae-9874-aa81b0534290",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transpose(Op):\n",
    "    ...\n",
    "\n",
    "@test\n",
    "def test_transpose_op_with_axes(op_class):\n",
    "    x = pt.tensor(\"x\", shape=(2, None, 4))\n",
    "    x_test = np.arange(2 * 3 * 4).reshape((2, 3, 4))\n",
    "\n",
    "    for axis, dtype in [\n",
    "        ((0, 2, 1), \"int64\"), \n",
    "        ((2, 0, 1), \"float32\")]:\n",
    "        op = op_class(axis)\n",
    "        out = op(x.astype(dtype))\n",
    "\n",
    "        assert out.type.ndim == 3\n",
    "        assert out.type.dtype == dtype\n",
    "        np.testing.assert_allclose(out.eval({x: x_test}), x_test.transpose(axis))\n",
    "\n",
    "# test_transpose_op_with_axes(Transpose)  # uncomment me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c78a38-4ce7-4514-beff-4d926999beab",
   "metadata": {},
   "source": [
    "### Exercise 3: Define operator equality using `__props__`\n",
    "\n",
    "PyTensor tries to avoid recomputing equivalent computations in a graph. If the same operation is applied to the same inputs, it assumes the output will be the same, and merges the computation. Here is an example using the Sum axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d6c15d1-976e-4387-b1dc-dc7dc031d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pt.vector(\"x\")\n",
    "out = sum(x) + sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c26ad47-ab04-40f7-8715-33a5d5ce5417",
   "metadata": {},
   "source": [
    "The original graph contains 2 distinct Sum operations (note the different ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76fd85ba-d57d-4195-a030-00e0b0bf6bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add [id A]\n",
      " ├─ Sum [id B]\n",
      " │  └─ x [id C]\n",
      " └─ Sum [id D]\n",
      "    └─ x [id C]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7f5b4e591c00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.dprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2173f4ee-d2a1-4aea-b01d-7f452f7df79b",
   "metadata": {},
   "source": [
    "But after rewriting only one sum is computed (note the same ids and the ellipsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30cd0072-1ecf-428e-82ca-4a094eb3bd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add [id A]\n",
      " ├─ Sum [id B]\n",
      " │  └─ x [id C]\n",
      " └─ Sum [id B]\n",
      "    └─ ···\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7f5b4e591c00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewrite_graph(out).dprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb99df31-120b-43b0-8371-b101c5c74011",
   "metadata": {},
   "source": [
    "However if we use different instances of the Sum Op PyTensor does not consider them equivalent and no merging is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53b475a6-bdd1-4783-8cd0-d08b48d78adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add [id A]\n",
      " ├─ Sum [id B]\n",
      " │  └─ x [id C]\n",
      " └─ Sum [id D]\n",
      "    └─ x [id C]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7f5b4e591c00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = Sum()(x) + Sum()(x)\n",
    "rewrite_graph(out).dprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058eb9a1-ee07-4c2a-82db-1b5074340366",
   "metadata": {},
   "source": [
    "PyTensor uses Op equality to determine if two computations are equivalent. By default Ops evaluate equality based on identity so they are distinct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de6d2242-d7ef-423c-b98c-e52cb3a60b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sum() == Sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f5da98-26cd-4753-9809-a50fc89e58c7",
   "metadata": {},
   "source": [
    "This is not the case for the PyTensor implementation of Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b5963fd-ae84-40a7-9fbe-8a65a76fef51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.sum(x).owner.op == pt.sum(x).owner.op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e26aa404-0c89-4ee0-a370-f080df6c9584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add [id A]\n",
      " ├─ Sum{axes=None} [id B]\n",
      " │  └─ x [id C]\n",
      " └─ Sum{axes=None} [id B]\n",
      "    └─ ···\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7f5b4e591c00>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewrite_graph(pt.sum(x) + pt.sum(x)).dprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6d2797-b70d-4ef8-83c1-9947014654bf",
   "metadata": {},
   "source": [
    "The default way of implementing Op equality is to define `__props__`, a tuple of strings with the names of immutable instance properties that \"parametrize\" an `Op`.\n",
    "\n",
    "When an `Op` has `__props__`, PyTensor will check if the respective instance attributes are equal and if so, assume two Operations from the same class are equivalent. \n",
    "\n",
    "Our simplest implementation of Sum has no parametrization, so we can define an empty `__props__`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99ba7e22-17dd-4ec6-aaca-d281699877df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Sum(Op):\n",
    "    __props__ = ()\n",
    "\n",
    "    def make_node(self, x):\n",
    "        return Apply(self, [x], [pt.scalar()])\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        outputs[0][0] = inputs[0].sum()\n",
    "\n",
    "Sum() == Sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f09f978-1077-4a4c-97f9-f0a7df4dfe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add [id A]\n",
      " ├─ Sum [id B]\n",
      " │  └─ x [id C]\n",
      " └─ Sum [id B]\n",
      "    └─ ···\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7f5b4e591c00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewrite_graph(Sum()(x) + Sum()(x)).dprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a849a3-ca89-43d7-b8ba-c47420e56853",
   "metadata": {},
   "source": [
    "Extend the Transpose Op with `__props__` so that two instances with the same axis evaluate equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1259f680-a458-4c6b-b96e-9fabdf2a938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transpose(Op):\n",
    "    ...\n",
    "\n",
    "@test\n",
    "def test_transpose_op_with_axes_and_props(op_class):\n",
    "    x = pt.tensor(\"x\", shape=(2, None, 4))\n",
    "    x_test = np.arange(2 * 3 * 4).reshape((2, 3, 4))\n",
    "\n",
    "    assert len(op_class.__props__)\n",
    "    assert op_class(axis=(0, 2, 1)) == op_class(axis=(0, 2, 1))\n",
    "    assert op_class(axis=(0, 2, 1)) != op_class(axis=(2, 0, 1))\n",
    "\n",
    "# test_transpose_op_with_axes_and_props(Transpose)  # uncomment me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c0f3b-18bd-4494-a4a5-9010a03cade5",
   "metadata": {},
   "source": [
    "### Exercise 4, implement an Op that wraps `np.convolve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aeee3620-ea84-4027-a5c3-c1d20fecdb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolve(Op):\n",
    "    ...\n",
    "\n",
    "def test_convolve(op_class):\n",
    "    x = pt.vector(\"x\", shape=(None,))\n",
    "    y = pt.vector(\"y\", shape=(3,))\n",
    "    out = op_class()(x, y)\n",
    "\n",
    "    x_test = np.arange(10).astype(\"float64\")\n",
    "    y_test = np.array([0, 1, 2]).astype=(\"float64\")\n",
    "    res = out.eval({x: x_test, y: y_test}) \n",
    "                    \n",
    "    np.testing.assert_allclose(res, np.convolve(x_test, y_test))\n",
    "\n",
    "    res2 = out.eval({x: res, y: y_test})\n",
    "    np.testing.assert_allclose(res, np.convolve(res, y_test))\n",
    "\n",
    "# test_convolve(Convolve)  # uncomment me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc34d2-fa6b-448e-a810-55158a85485d",
   "metadata": {},
   "source": [
    "Extend the Op to include the parameter `mode` that `np.convolve` also offers.\n",
    "\n",
    "Extra points if the output shape is specified when that's possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "355acf46-d232-4368-9d96-e63378da3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolve(Op):\n",
    "    ...\n",
    "\n",
    "def test_convolve(op_class):\n",
    "    x = pt.vector(\"x\", shape=(10,))\n",
    "    y = pt.vector(\"y\", shape=(3,))\n",
    "\n",
    "    x_test = np.arange(10).astype(\"float64\")\n",
    "    y_test = np.array([0, 1, 2]).astype=(\"float64\")\n",
    "\n",
    "    for mode in (\"full\", \"valid\", \"same\"):\n",
    "        print(f\"{mode=}\")\n",
    "        op = op_class(mode=mode)\n",
    "        assert op == op_class(mode=mode)\n",
    "        \n",
    "        out = op(x, y)\n",
    "        if out.type.shape != (None,):\n",
    "            assert out.type.shape == np.convolve(x_test, y_test, mode=mode).shape\n",
    "\n",
    "\n",
    "        res = out.eval({x: x_test, y: y_test})             \n",
    "        np.testing.assert_allclose(res, np.convolve(x_test, y_test, mode=mode))\n",
    "\n",
    "# test_convolve(Convolve)  # uncomment me"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytensor",
   "language": "python",
   "name": "pytensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
