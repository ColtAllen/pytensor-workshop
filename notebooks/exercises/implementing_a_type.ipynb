{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqjEZhDST8FnLY4W2/dZqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pymc-devs/pytensor-workshop/blob/main/notebooks/exercises/implementing_a_type.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ðŸ’¡ To better engage gray mass we suggest you turn off Colab AI autocompletion in `Tools > Settings > AI Assistance`**"
      ],
      "metadata": {
        "id": "vfc5gS281Z9R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6kRJ_NXIsk5m"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "try:\n",
        "    import pytensor_workshop\n",
        "except ModuleNotFoundError:\n",
        "    !pip install git+https://github.com/pymc-devs/pytensor-workshop.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# These exercises become tricker if we allow default inplace operations\n",
        "# If this itches your curiosity, check:\n",
        "# https://pytensor.readthedocs.io/en/latest/extending/inplace.html\n",
        "%set_env PYTENSOR_FLAGS=\"optimizer_excluding=inplace\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjFtdt9GH3qu",
        "outputId": "1ebee230-6a6a-41eb-ee4e-6762beceee55"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTENSOR_FLAGS=\"optimizer_excluding=inplace\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Sequence\n",
        "from copy import deepcopy\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "plUZxrtJwhkZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytensor\n",
        "import pytensor.tensor as pt\n",
        "from pytensor.graph import Apply, Variable, rewrite_graph\n",
        "from pytensor.graph.fg import FunctionGraph\n",
        "from pytensor.graph.op import Op\n",
        "from pytensor.graph.rewriting.basic import out2in\n",
        "from pytensor.graph.type import Type\n",
        "from pytensor.tensor.type import TensorType"
      ],
      "metadata": {
        "id": "2JtifJXCsspU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytensor_workshop import test"
      ],
      "metadata": {
        "id": "HUB7tr_VsrCe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing a tuple type"
      ],
      "metadata": {
        "id": "sggudXRitWLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the walkthough, we saw how implementing new variable types in PyTensor may look like. In this exercise we will implement a real novel pytensor type: Tuples!"
      ],
      "metadata": {
        "id": "QBAvFM4Jvgs4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Types in PyTensor require one method: `filter`. This method is responsible for accepting or rejecting concrete data as being compatible with the specified type.\n",
        "\n",
        "It can also be given permission to convert the data into the appropriate type if `strict=False`.\n",
        "\n",
        "To be able to fully work with Tuples in PyTensor we need to know something about the types contained inside (this will be clear next). For this reason we parametrize each `TupleType` with a sequence of `Type`s."
      ],
      "metadata": {
        "id": "N2JWB8Wdy2jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TupleType(Type[tuple]):\n",
        "    def __init__(self, entry_types: Sequence[Type]):\n",
        "        self.entry_types = entry_types\n",
        "\n",
        "    def filter(\n",
        "        self,\n",
        "        data: \"Any\",\n",
        "        strict: bool = False,\n",
        "        allow_downcast: bool | None = None\n",
        "    ) -> tuple:\n",
        "        \"\"\"Return data or an appropriately wrapped/converted data.\n",
        "\n",
        "        Subclass implementations should raise a TypeError exception if\n",
        "        the data is not of an acceptable type.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data:\n",
        "            The data to be filtered/converted.\n",
        "        strict: bool (optional)\n",
        "            If ``True``, the data returned must be the same as the\n",
        "            data passed as an argument.\n",
        "        allow_downcast: bool (optional)\n",
        "            If `strict` is ``False``, and `allow_downcast` is ``True``, the\n",
        "            data may be cast to an appropriate type. If `allow_downcast` is\n",
        "            ``False``, it may only be up-cast and not lose precision. If\n",
        "            `allow_downcast` is ``None`` (default), the behaviour can be\n",
        "            type-dependent, but for now it means only Python floats can be\n",
        "            down-casted, and only to floatX scalars.\n",
        "        \"\"\"\n",
        "        if not isinstance(data, tuple):\n",
        "            if strict:\n",
        "                raise TypeError(\"data should be a tuple\")\n",
        "            elif isinstance(data, list):\n",
        "                data = tuple(data)\n",
        "            else:\n",
        "                raise TypeError(\"cannot convert data to tuple\")\n",
        "\n",
        "        if len(data) != len(self.entry_types):\n",
        "            raise TypeError(f\"data should be a tuple of length {len(self.entry_types)}\")\n",
        "\n",
        "        data = tuple(\n",
        "            entry_type.filter(entry, strict=strict, allow_downcast=allow_downcast)\n",
        "            for entry, entry_type in zip(data, self.entry_types)\n",
        "        )\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"{tuple(str(t) for t in self.entry_types)}\""
      ],
      "metadata": {
        "id": "w0l2zUFmt3gC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's implement a tuple type that contains one vector and one matrix (or arbitrary size)"
      ],
      "metadata": {
        "id": "AjNTl2bCzynX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector = TensorType(shape=(None,), dtype=\"float64\", name=\"vector\")\n",
        "matrix = TensorType(shape=(None, None), dtype=\"float64\", name=\"matrix\")\n",
        "vec_mat_tuple_type = TupleType([vector, matrix])"
      ],
      "metadata": {
        "id": "8uVsKFi-yBWy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now define a variable of this type, that we can hopefully evaluate"
      ],
      "metadata": {
        "id": "54XC5mMlz8Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xy = vec_mat_tuple_type(\"(x,y)\")\n",
        "xy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMuZDvUEySGU",
        "outputId": "dbe806af-e53f-4a8d-bdbc-cb5904685320"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(x,y)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xy.eval({xy: ([1, 1], [[1, 2], [3, 4]])})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZuHetbHzDE2",
        "outputId": "a5f30eec-1112-4de8-940a-a6e2480e1981"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 1.]),\n",
              " array([[1., 2.],\n",
              "        [3., 4.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The filter method will trigger when we try to provide a value that is not compatible with the type"
      ],
      "metadata": {
        "id": "gC5BefEB0eYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    xy.eval({xy: ([[1, 2], [3, 4]], [1, 1])})\n",
        "except TypeError as exc:\n",
        "    print(exc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xayc9Xez0AV8",
        "outputId": "0a5e5f8c-fc08-4ecd-8d68-a758fe65f02c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bad input argument to pytensor function with name \"<ipython-input-9-45228ad6e6c0>:1\" at index 0 (0-based).  \n",
            "Backtrace when that variable is created:\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-8-498bb65cf53c>\", line 1, in <cell line: 0>\n",
            "    xy = vec_mat_tuple_type(\"(x,y)\")\n",
            "Wrong number of dimensions: expected 1, got 2 with shape (2, 2).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having new types is not very interesting if we can't do anything symbolically with them. So let's implement two basic operations to create and select from tuples:"
      ],
      "metadata": {
        "id": "PawzQ5EB0itj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PackTuple(Op):\n",
        "    \"\"\"Pack arbitrary PyTensor variables into a tuple\"\"\"\n",
        "\n",
        "    def make_node(self, *inputs):\n",
        "        # Define a new tuple type and variable\n",
        "        output_tuple_type = TupleType([inp.type for inp in inputs])\n",
        "        output = output_tuple_type()\n",
        "        return Apply(self, inputs, [output])\n",
        "\n",
        "    def perform(self, node, inputs, output_storage):\n",
        "        output_storage[0][0] = tuple(inputs)\n",
        "\n",
        "pack_tuple = PackTuple()"
      ],
      "metadata": {
        "id": "lMoV6csCuXaY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = pt.arange(3)\n",
        "y = pt.zeros(7)\n",
        "xy = pack_tuple(x, y)\n",
        "xxy = pack_tuple(x, xy)\n",
        "xxy.dprint()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO50JRnX2FwX",
        "outputId": "2377c787-2cab-47c6-8619-d72cbefdc26f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PackTuple [id A]\n",
            " â”œâ”€ ARange{dtype='int64'} [id B]\n",
            " â”‚  â”œâ”€ 0 [id C]\n",
            " â”‚  â”œâ”€ 3 [id D]\n",
            " â”‚  â””â”€ 1 [id E]\n",
            " â””â”€ PackTuple [id F]\n",
            "    â”œâ”€ ARange{dtype='int64'} [id B]\n",
            "    â”‚  â””â”€ Â·Â·Â·\n",
            "    â””â”€ Alloc [id G]\n",
            "       â”œâ”€ 0.0 [id H]\n",
            "       â””â”€ 7 [id I]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ipykernel.iostream.OutStream at 0x7d6f2d345030>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xxy.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjR9rASn3Ul9",
        "outputId": "5228a58d-1fbe-49e8-d5a1-fee8ad7201ab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2]), (array([0, 1, 2]), array([0., 0., 0., 0., 0., 0., 0.])))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: Implement an Op that selects an entry from a Tuple"
      ],
      "metadata": {
        "id": "QGqIN8Xq_Gh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the `make_node` and `perform` for the `SelectTuple` `Op` below.\n",
        "Given a static index it should select the corresponding entry from a symbolic tuple."
      ],
      "metadata": {
        "id": "YUUZtMxMwXbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelectTuple(Op):\n",
        "    \"\"\"Select an entry from a PyTensor tuple\"\"\"\n",
        "    __props__ = (\"idx\",)\n",
        "\n",
        "    def __init__(self, idx: int):\n",
        "        self.idx = idx\n",
        "\n",
        "    def make_node(self, tpl):\n",
        "        ...\n",
        "\n",
        "    def perform(self, node, inputs, output_storage):\n",
        "        ...\n",
        "\n",
        "@test\n",
        "def test_select_tuple(selecet_op_class):\n",
        "    x = pt.arange(3)\n",
        "    y = pt.zeros(7)\n",
        "    xy = pack_tuple(x, y)\n",
        "    xxy = pack_tuple(x, xy)\n",
        "\n",
        "    y_again = selecet_op_class(1)(selecet_op_class(1)(xxy))\n",
        "    assert y_again.type == y.type\n",
        "    y_again.dprint()\n",
        "\n",
        "    np.testing.assert_allclose(y_again.eval(), np.zeros((7,)))\n",
        "    np.testing.assert_allclose(y_again.eval({y: np.arange(7)}), np.arange(7))\n",
        "\n",
        "# test_select_tuple(SelectTuple)  # uncomment me"
      ],
      "metadata": {
        "id": "dfLtVpYS_stL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2: Use the new tuple type\n",
        "\n",
        "Compile a pytensor function that takes a tuple with a vector and matrix as inputs, squares the first and cubes the second, and packs them back as a tuple in reversed order"
      ],
      "metadata": {
        "id": "WGNhyK-j3jVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = ...\n",
        "out = ...\n",
        "# fn = pytensor.function(inputs=[inp], outputs=[out])\n",
        "\n",
        "@test\n",
        "def test_tuple_function(fn):\n",
        "    from pytensor.compile.function.types import Function\n",
        "    assert isinstance(fn, Function)\n",
        "    assert isinstance(fn.maker.fgraph.inputs[0].type, TupleType)\n",
        "    assert isinstance(fn.maker.fgraph.outputs[0].type, TupleType)\n",
        "\n",
        "    x_size = np.random.poisson(7)\n",
        "    x_test = np.random.normal(size=x_size)\n",
        "    y_size = np.random.poisson(7, size=(2,))\n",
        "    y_test = np.abs(np.random.normal(size=y_size))\n",
        "\n",
        "    [(out_1, out_2)] = fn((x_test, y_test))\n",
        "    np.testing.assert_allclose(out_2, x_test**2)\n",
        "    np.testing.assert_allclose(out_1, y_test**3)\n",
        "\n",
        "# test_tuple_function(fn)  # uncomment me"
      ],
      "metadata": {
        "id": "sHYzMJGZ5uNI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3: Define a rewrite that undoes a SelectTuple(PackTuple)\n",
        "\n",
        "PyTensor existing machinery has little ability to reason about graphs that contain our newly defite tuple type.\n",
        "\n",
        "One thing it can do, is constant fold the operations we defined on tuples.\n",
        "\n"
      ],
      "metadata": {
        "id": "zJAxhc9D5oX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment me when SelectTuple is implemented\n",
        "\n",
        "# x = pt.arange(3)\n",
        "# y = pt.zeros(7)\n",
        "# xy = pack_tuple(x, y)\n",
        "# xxy = pack_tuple(x, xy)\n",
        "# y_again = SelectTuple(1)(SelectTuple(1)(xxy))\n",
        "\n",
        "# with pytensor.config.change_flags(optimizer_verbose=True):\n",
        "#     rewrite_graph(y_again).dprint()"
      ],
      "metadata": {
        "id": "jQ2SbgJY603-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But if we have something less static, it can't do much. For example the next graph should be equivalent to zero, but PyTensor cannot figure that out because it can't see through the sequence of SelectTuple(PackTuple).\n",
        "\n",
        "It cannot constant_fold, because `x` is not a constant."
      ],
      "metadata": {
        "id": "7Fx_ntwS7Ifr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment me when SelectTuple is implemented\n",
        "\n",
        "# x = pt.scalar(\"x\")\n",
        "# x1 = pack_tuple(x, pt.ones(()))\n",
        "# x_again = SelectTuple(0)(x1)\n",
        "# out = x - x_again\n",
        "# out.dprint()\n",
        "\n",
        "# print()\n",
        "\n",
        "# rewrite_graph(out).dprint()"
      ],
      "metadata": {
        "id": "Hhvi2B3x7Hub"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should fill in the `select_entry_of_packed_tuple` node rewriter, so that it undoes a SelectTuple(PackTuple).\n",
        "\n",
        "The function should return None when the node in question does not match the pattern we care about, and should return a list containing the variable(s) that we want to replace the output node with, when it does match the pattern."
      ],
      "metadata": {
        "id": "t1H7FVAk7zYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytensor.graph.rewriting.basic import out2in, node_rewriter\n",
        "\n",
        "@node_rewriter(tracks=None)\n",
        "def select_entry_of_packed_tuple(fgraph, node) -> list[Variable] | None:\n",
        "    \"\"\"Rewrite SelectTuple(idx)(PackTuple()(tpl)) -> tpl[idx]\"\"\"\n",
        "    ...\n",
        "\n",
        "@test\n",
        "def test_useless_pack_tuple(rewrite_fn):\n",
        "    from pytensor.graph.rewriting.basic import EquilibriumGraphRewriter\n",
        "    from pytensor.tensor.rewriting.math import local_add_canonizer\n",
        "    from pytensor.tensor.rewriting.basic import constant_folding\n",
        "    from pytensor.graph.rewriting.utils import equal_computations\n",
        "\n",
        "    # Define a graph rewriter that applies the following 3 rewrites until an equilibrium is achieved\n",
        "    rewrite = EquilibriumGraphRewriter([select_entry_of_packed_tuple, local_add_canonizer, constant_folding], max_use_ratio=3)\n",
        "\n",
        "    # Test that using those 3 rewrites, pytensor concludes the output equals zero\n",
        "    x = pt.scalar(\"x\")\n",
        "    x1 = pack_tuple(x, pt.ones(()))\n",
        "    x_again = SelectTuple(0)(x1)\n",
        "    out = x - x_again\n",
        "\n",
        "    fg = FunctionGraph(outputs=[out], clone=False)\n",
        "    with pytensor.config.change_flags(optimizer_verbose=True):\n",
        "        rewrite.apply(fg)\n",
        "    [rewritten_out] = fg.outputs\n",
        "    rewritten_out.dprint()\n",
        "\n",
        "    assert equal_computations([rewritten_out], [pt.constant(np.array(0.0))])\n",
        "\n",
        "    # Test that rewrite does not cause any failure in a case where it can't be applied\n",
        "    scalar = pt.TensorType(\"float64\", shape=())\n",
        "    xx = TupleType([scalar, scalar])()\n",
        "    out = SelectTuple(0)(xx) * 2\n",
        "\n",
        "    fg = FunctionGraph(outputs=[out], clone=False)\n",
        "    rewrite.apply(fg)\n",
        "    [rewritten_out] = fg.outputs\n",
        "\n",
        "    assert equal_computations([out], [rewritten_out])\n",
        "\n",
        "# test_useless_pack_tuple(select_entry_of_packed_tuple)  # uncomment me"
      ],
      "metadata": {
        "id": "VZoLzYjt75-E"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4: Allow symbolic indexing on tuple\n",
        "\n",
        "Define a new SelectTuple Op where the indexing position is symbolic (shows up as a second input to the apply node).\n",
        "\n",
        "What constraints are needed on the input tuple type for this to be a well defined operation at compile type?\n",
        "\n",
        "A TypeError should be raised when such constraints aren't met."
      ],
      "metadata": {
        "id": "arjUA7u23_oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SymbolicSelectTuple(Op):\n",
        "    \"\"\"Select an entry from a PyTensor tuple\"\"\"\n",
        "    __props__ = ()\n",
        "\n",
        "    def make_node(self, tpl, idx):\n",
        "        ...\n",
        "\n",
        "    def perform(self, node, inputs, output_storage):\n",
        "        ...\n",
        "\n",
        "@test\n",
        "def test_symbolic_select_tuple(select_op_class):\n",
        "    select_op = select_op_class()\n",
        "\n",
        "    vector_type = pt.TensorType(shape=(None,), dtype=\"float64\", name=\"vector\")\n",
        "    vec_vec_tuple_type = TupleType([vector_type, vector_type])\n",
        "\n",
        "    # Check Op semantics are correctly implemented\n",
        "    idx = pt.scalar(\"idx\", dtype=\"int64\")\n",
        "    xx = vec_vec_tuple_type(\"(x,x)\")\n",
        "    y = select_op(xx, idx)\n",
        "    assert y.type == vector_type  # Only possible result\n",
        "\n",
        "    # Try to evaluate it\n",
        "    xx_test = ([0, 1], [2, 3, 4])\n",
        "    np.testing.assert_allclose(\n",
        "        y.eval({xx: xx_test, idx:0}),\n",
        "        [0, 1],\n",
        "    )\n",
        "\n",
        "    # Test case that cannot possibly be disambiguated at compile time\n",
        "    matrix_type = pt.TensorType(shape=(None, None), dtype=\"float64\", name=\"matrix\")\n",
        "    vec_mat_tuple_type = TupleType([vector_type, matrix_type])\n",
        "    try:\n",
        "        xy = vec_mat_tuple_type(\"(x,y)\")\n",
        "        select_op(xy, idx)\n",
        "    except TypeError as exc:\n",
        "        pass\n",
        "    else:\n",
        "        assert 0, \"Should have raised a TypeError\"\n",
        "\n",
        "    # Trickier case that should be valid\n",
        "    nested_vec_vec_tuple_type = TupleType([vec_vec_tuple_type, vec_vec_tuple_type])\n",
        "    nested_xx = nested_vec_vec_tuple_type(\"((x,x),(x,x))\")\n",
        "\n",
        "    xx = select_op(nested_xx, idx)\n",
        "    assert xx.type == vec_vec_tuple_type\n",
        "\n",
        "    x = select_op(xx, 1-idx)\n",
        "    assert x.type == vector_type\n",
        "\n",
        "    nested_xx_test_value = (\n",
        "        ([0, 1], [2, 3, 4]),\n",
        "        ([4, 5, 6, 7], [8, 9, 10, 11, 12]),\n",
        "    )\n",
        "    np.testing.assert_allclose(\n",
        "        x.eval({nested_xx: nested_xx_test_value, idx: 0}),\n",
        "        [2, 3, 4],\n",
        "    )\n",
        "\n",
        "\n",
        "# test_symbolic_select_tuple(SymbolicSelectTuple)  # uncomment me"
      ],
      "metadata": {
        "id": "vDg26FLomd47"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Open-ended challenge: implement your new type and a basic operation on it.\n",
        "\n",
        "If you got a feel for how to work with non-array types in PyTensor, we challenge you to try to implement yet another type that speaks to you.\n",
        "\n",
        "Here are some suggestions:\n",
        "* Strings and find operation\n",
        "* [Xarray DataArray](https://docs.xarray.dev/en/latest/getting-started-guide/quick-overview.html) with a dim-based broadcasting or indexing operation\n",
        "* [Numpy polynomials](https://numpy.org/doc/stable/reference/routines.polynomials.html) with addition operation\n",
        "* [Sparse COO matrices](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_array.html#scipy.sparse.coo_array) and expm1 operation\n",
        "* Anything else you fancy\n"
      ],
      "metadata": {
        "id": "zY3hHuvDv2es"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LWpjTUwazNx8"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}